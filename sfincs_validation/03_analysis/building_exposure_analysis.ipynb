{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e14187d8-2a36-4c94-973b-e84457bb5376",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import fiona\n",
    "import xarray as xr\n",
    "import matplotlib as mpl\n",
    "import hydromt\n",
    "from hydromt import DataCatalog\n",
    "import hydromt_sfincs\n",
    "from hydromt_sfincs import SfincsModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c6ae255-d38b-45db-89ff-c8d3de0eac87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in SFINCS model: ENC_200m_sbg5m_avgN_adv1_eff75\n"
     ]
    }
   ],
   "source": [
    "# Filepath to data catalog yml\n",
    "cat_dir = r'Z:\\users\\lelise\\data'\n",
    "yml_base_CONUS = os.path.join(cat_dir, 'data_catalog_BASE_CONUS.yml')\n",
    "yml_base_Carolinas = os.path.join(cat_dir, 'data_catalog_BASE_Carolinas.yml')\n",
    "yml_sfincs_Carolinas = os.path.join(cat_dir, 'data_catalog_SFINCS_Carolinas.yml')\n",
    "os.chdir(r'Z:\\users\\lelise\\projects\\Carolinas_SFINCS\\Chapter1_FlorenceValidation\\sfincs_models\\mod_v4_flor')\n",
    "model_root = r'ENC_200m_sbg5m_avgN_adv1_eff75'\n",
    "mod = SfincsModel(model_root, mode='r', data_libs=[yml_base_CONUS, yml_base_Carolinas, yml_sfincs_Carolinas])\n",
    "cat = mod.data_catalog\n",
    "print(f'Reading in SFINCS model: {model_root}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac0e4a12-f554-4226-8d4a-1e5c81434323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading downscaled floodmaps at 200m resolution (created with downscale_floodmaps.py) and the subgrid.\n",
      "Reading in peak water levels and the difference in compound minus individual dirvers/processes.\n"
     ]
    }
   ],
   "source": [
    "# Load in preprocessed model results to extract at the buildings including \n",
    "# (1) downscaled eak flood depths (2) peak water levels (3) compound peak water level minus max individual processes/driver\n",
    "\n",
    "res = 200\n",
    "da = xr.open_dataset(os.path.join(os.getcwd(), 'floodmaps', f'{res}m', 'floodmaps.nc'))\n",
    "dep = xr.open_dataset(os.path.join(os.getcwd(), 'subgrid', 'dep_subgrid.tif'))\n",
    "print(f'Reading downscaled floodmaps at {res}m resolution (created with downscale_floodmaps.py) and the subgrid.')\n",
    "\n",
    "# Create output directory if it doesn't already exist\n",
    "out_dir = os.path.join(os.getcwd(), 'process_attribution', f'{res}m')\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "os.chdir(out_dir)\n",
    "\n",
    "# Load files created using \"compound_flooding_analysis.py\" script\n",
    "da_class = xr.open_dataarray('flor_peakWL_attributed_all.nc')\n",
    "da_diff = xr.open_dataset('flor_peakWL_compound_minus_maxIndiv_all.nc')\n",
    "print(f'Reading in peak water levels and the difference in compound minus individual dirvers/processes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dd113cb-8ab0-4051-b882-f95e765f2a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' PART 1 - Determine damage status using NFIP claims/policy data at each structure'''\n",
    "# Read in area of interest shapefile and/or model domain to clip\n",
    "studyarea_gdf = mod.region.to_crs(epsg=32617)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba9f55ad-59f3-4603-a77c-5c83b28df963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NC Buildings in Study Area: 1488229\n"
     ]
    }
   ],
   "source": [
    "# Read in structures information and clip to the study area. This might take a little while and only needs to be run once...\n",
    "# Read in structures information and clip to the study area\n",
    "nc_buildings = gpd.read_file(r'Z:\\users\\lelise\\data\\storm_data\\hurricanes\\X_observations\\nfip_flood_damage_NC'\n",
    "                             r'\\included_data.gdb',\n",
    "                             layer='buildings',\n",
    "                             mask=studyarea_gdf).to_crs(studyarea_gdf.crs)\n",
    "nc_buildings['STATE'] = 'NC'\n",
    "b1 = nc_buildings.drop(nc_buildings.columns[~nc_buildings.columns.isin(['STATE', 'geometry'])], axis=1)\n",
    "print('Number of NC Buildings in Study Area:', str(len(nc_buildings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b93fc40-d6ca-4f22-978e-ef2cee9570b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of SC Buildings in Study Area: 428051\n"
     ]
    }
   ],
   "source": [
    "# Load SC buildings from NSI. This might take a little while and only needs to be run once...\n",
    "sc_buildings = gpd.read_file(r'Z:\\users\\lelise\\data\\geospatial\\infrastructure\\nsi_2022_45.gpkg',\n",
    "                             mask=studyarea_gdf).to_crs(studyarea_gdf.crs)\n",
    "sc_buildings['STATE'] = 'SC'\n",
    "b2 = sc_buildings.drop(sc_buildings.columns[~sc_buildings.columns.isin(['STATE', 'geometry'])], axis=1)\n",
    "print('Number of SC Buildings in Study Area:', str(len(sc_buildings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70c556c7-6a6f-45ad-8e00-021111a333ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Buildings in Study Area: 1916280\n"
     ]
    }
   ],
   "source": [
    "# Combine NC and SC data into single dataframe\n",
    "buildings = pd.concat(objs=[b1, b2], axis=0, ignore_index=True)\n",
    "print('Number of Buildings in Study Area:', str(len(buildings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "414a8242-a71f-4ce8-8af0-b34001791830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               geometry   STATE  index_right    HUC6\n",
      "Name                                                \n",
      "Cape Fear        472089  472089       472089  472089\n",
      "Lower Pee Dee    660780  660780       660780  660780\n",
      "Neuse            379586  379586       379586  379586\n",
      "Onslow Bay       199696  199696       199696  199696\n",
      "Pamlico          200523  200523       200523  200523\n"
     ]
    }
   ],
   "source": [
    "# Join buildings data to HUC6 watershed, this will take a while...\n",
    "basins = cat.get_geodataframe(\n",
    "    r'Z:\\users\\lelise\\data\\geospatial\\hydrography\\nhd\\NHD_H_North_Carolina_State_Shape\\Shape\\WBDHU6.shp')\n",
    "basins = basins[basins['Name'].isin(['Pamlico', 'Neuse', 'Onslow Bay', 'Cape Fear', 'Lower Pee Dee'])]\n",
    "basins.to_crs(epsg=32617, inplace=True)\n",
    "basins = basins[[\"HUC6\", \"Name\", \"geometry\"]]\n",
    "buildings = gpd.tools.sjoin(left_df=buildings, right_df=basins, how='left')\n",
    "\n",
    "print(buildings.groupby('Name').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c80efb2a-f5cf-420f-b15c-1ca9cc38acdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' PART 2 - Extract flood depths and process attribution '''\n",
    "gdf = buildings.copy()\n",
    "gdf['xcoords'] = gdf['geometry'].x.to_xarray()\n",
    "gdf['ycoords'] = gdf['geometry'].y.to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01b8a442-44d8-4e99-a779-7f200ff56615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['compound' 'coastal' 'runoff' 'discharge' 'rainfall' 'stormTide' 'wind']\n"
     ]
    }
   ],
   "source": [
    "# Rename run IDs \n",
    "rename = ['compound','coastal','runoff','discharge','rainfall','stormTide','wind']\n",
    "da['run'] = xr.IndexVariable('run', rename) \n",
    "print(da.run.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0c69b9b-21c8-49f5-ae3f-edf610275534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract water depths from compound scenario\n",
    "da_fldp = da.sel(run='compound')\n",
    "hmax = da_fldp['hmax'].sel(x=gdf['geometry'].x.to_xarray(), y=gdf['geometry'].y.to_xarray(), method='nearest').values\n",
    "gdf['hmax'] = hmax.transpose()\n",
    "\n",
    "# Extract water depths from coastal scenario\n",
    "da_fldp = da.sel(run='coastal')\n",
    "hmax = da_fldp['hmax'].sel(x=gdf['geometry'].x.to_xarray(), y=gdf['geometry'].y.to_xarray(), method='nearest').values\n",
    "gdf['hmax_coastal'] = hmax.transpose()\n",
    "\n",
    "# Extract water depths from compound scenario\n",
    "da_fldp = da.sel(run='runoff')\n",
    "hmax = da_fldp['hmax'].sel(x=gdf['geometry'].x.to_xarray(), y=gdf['geometry'].y.to_xarray(), method='nearest').values\n",
    "gdf['hmax_runoff'] = hmax.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b632c3b3-c389-471a-9a62-d74809110414",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'transpose'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Extract diff in compound minus max individual\u001b[39;00m\n\u001b[0;32m      6\u001b[0m hmax_diff \u001b[38;5;241m=\u001b[39m da_diff\u001b[38;5;241m.\u001b[39msel(x\u001b[38;5;241m=\u001b[39mgdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mto_xarray(), y\u001b[38;5;241m=\u001b[39mgdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mto_xarray(), method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m----> 7\u001b[0m gdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhmax_diff\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mhmax_diff\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Extract gnd elevation at buildings\u001b[39;00m\n\u001b[0;32m     10\u001b[0m depv \u001b[38;5;241m=\u001b[39m dep\u001b[38;5;241m.\u001b[39msel(x\u001b[38;5;241m=\u001b[39mgdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mto_xarray(), y\u001b[38;5;241m=\u001b[39mgdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mto_xarray(), method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'transpose'"
     ]
    }
   ],
   "source": [
    "# Extract attribution code\n",
    "hmax_class = da_class.sel(x=gdf['geometry'].x.to_xarray(), y=gdf['geometry'].y.to_xarray(), method='nearest').values\n",
    "gdf['hmax_class'] = hmax_class.transpose()\n",
    "\n",
    "# Extract diff in compound minus max individual\n",
    "hmax_diff = da_diff.sel(x=gdf['geometry'].x.to_xarray(), y=gdf['geometry'].y.to_xarray(), method='nearest').values\n",
    "gdf['hmax_diff'] = hmax_diff.transpose()\n",
    "\n",
    "# Extract gnd elevation at buildings\n",
    "depv = dep.sel(x=gdf['geometry'].x.to_xarray(), y=gdf['geometry'].y.to_xarray(), method='nearest').values\n",
    "gdf['gnd_elev'] = depv.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8c7479-8bef-452c-bc2d-d32486b96bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all building data\n",
    "gdf2 = gdf.copy()\n",
    "gdf2.to_csv(os.path.join(out_dir, 'building_pts_with_depth.csv'))\n",
    "\n",
    "# Save buildings that had flooding greater than 0\n",
    "gdf = gdf[gdf['hmax_class'] > 0]\n",
    "gdf.to_csv(os.path.join(out_dir, 'building_pts_with_depth_floodedOnly.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2f5d58-6263-4b79-8496-3dd411c98716",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Part 3 - Get STATS '''\n",
    "# Reclass coastal compound and runoff compound to 5\n",
    "gdf['hmax_class'][gdf['hmax_class'] == 2] = 5\n",
    "gdf['hmax_class'][gdf['hmax_class'] == 4] = 5\n",
    "\n",
    "mast_stats = pd.DataFrame()\n",
    "for threshold in [0, 0.15, 0.5, 1.0, 1.5]:\n",
    "    for classification in [1, 3, 5]:\n",
    "        sub = gdf[gdf['hmax_class'] == classification]\n",
    "        sub = sub[sub['hmax'] > threshold]\n",
    "        dep_stats = pd.DataFrame(sub['hmax'].describe(percentiles=[0.05, 0.10, 0.50, 0.90, 0.95])).T\n",
    "        gnd_dep_stats = pd.DataFrame(sub['gnd_elev'].describe(percentiles=[0.05, 0.10, 0.50, 0.90, 0.95])).T\n",
    "        dep_dif_stats = pd.DataFrame(sub['hmax_diff'].describe(percentiles=[0.05, 0.10, 0.50, 0.90, 0.95])).T\n",
    "\n",
    "        df = pd.concat([dep_stats, dep_dif_stats, gnd_dep_stats], axis=0, ignore_index=True)\n",
    "        df['dep_thresh'] = threshold\n",
    "        df['class'] = classification\n",
    "        df['stat_ID'] = ['hmax', 'hmax_diff', 'gnd_elev']\n",
    "\n",
    "        mast_stats = pd.concat([mast_stats, df], axis=0, ignore_index=True)\n",
    "mast_stats = mast_stats.round(2)\n",
    "mast_stats.to_csv(os.path.join(out_dir, 'building_depth_stats_byClass_Threshold.csv'), index=False)\n",
    "print(mast_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a52114-a577-47aa-a64a-f44b306721f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mast_stats = pd.DataFrame()\n",
    "for threshold in [0, 0.15, 1.0]:\n",
    "    for classification in [1, 3, 5]:\n",
    "        sub = gdf[gdf['hmax_class'] == classification]\n",
    "        sub = sub[sub['hmax'] > threshold]\n",
    "        dep_stats = pd.DataFrame(sub.groupby('Name')['hmax'].describe(percentiles=[0.05, 0.10, 0.50, 0.90, 0.95]))\n",
    "        dep_stats['Name'] = dep_stats.index\n",
    "        dep_stats['dep_thresh'] = threshold\n",
    "        dep_stats['type'] = 'hmax'\n",
    "        dep_stats['classification'] = classification\n",
    "\n",
    "        dep_dif_stats = pd.DataFrame(\n",
    "            sub.groupby('Name')['hmax_diff'].describe(percentiles=[0.05, 0.10, 0.50, 0.90, 0.95]))\n",
    "        dep_dif_stats['Name'] = dep_dif_stats.index\n",
    "        dep_dif_stats['dep_thresh'] = threshold\n",
    "        dep_dif_stats['type'] = 'hmax_diff'\n",
    "        dep_dif_stats['classification'] = classification\n",
    "\n",
    "        gnd_dep_stats = pd.DataFrame(\n",
    "            sub.groupby('Name')['gnd_elev'].describe(percentiles=[0.05, 0.10, 0.50, 0.90, 0.95]))\n",
    "        gnd_dep_stats['Name'] = gnd_dep_stats.index\n",
    "        gnd_dep_stats['dep_thresh'] = threshold\n",
    "        gnd_dep_stats['type'] = 'gnd_elev'\n",
    "        gnd_dep_stats['classification'] = classification\n",
    "\n",
    "        df = pd.concat([dep_stats, dep_dif_stats, gnd_dep_stats], axis=0, ignore_index=True)\n",
    "\n",
    "        mast_stats = pd.concat([mast_stats, df], axis=0, ignore_index=True)\n",
    "\n",
    "mast_stats = mast_stats.round(2)\n",
    "mast_stats.to_csv(os.path.join(out_dir, 'building_depth_stats_byClass_Threshold_byHUC.csv'), index=False)\n",
    "print(mast_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3b86e4-de0a-44f8-84da-2394e9e8dbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Part 4 - Plotting '''\n",
    "gdf['group'] = ''\n",
    "gdf['group'][gdf['hmax_class'] == 1] = 'Coastal'\n",
    "gdf['group'][gdf['hmax_class'] == 3] = 'Runoff'\n",
    "gdf['group'][gdf['hmax_class'] == 5] = 'Compound'\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0068b09-a773-4321-b26d-3edf9eca5bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family': 'Arial', 'size': 10}\n",
    "mpl.rc('font', **font)\n",
    "mpl.rcParams.update({'axes.titlesize': 10})\n",
    "flierprops = dict(marker='+', markerfacecolor='none', markersize=3, markeredgecolor='black')\n",
    "medianprops = dict(linestyle='-', linewidth=2, color='black')\n",
    "meanpointprops = dict(marker='D', markeredgecolor='black', markerfacecolor='lightgrey', markersize=4)\n",
    "for threshold in [0.15, 1]:\n",
    "    ds = gdf[gdf['hmax_class'] > 0]\n",
    "    ds = ds[ds['hmax'] > threshold]\n",
    "    bb = ['Lower Pee Dee', 'Cape Fear', 'Onslow Bay', 'Neuse', 'Pamlico', 'Domain']\n",
    "    fig, axs = plt.subplots(nrows=3, ncols=2, tight_layout=True, figsize=(6.2, 5),\n",
    "                            sharex=True, sharey=False)\n",
    "    axs = axs.flatten()\n",
    "    for i in range(len(bb)):\n",
    "        ax = axs[i]\n",
    "        if i == 5:\n",
    "            dsb = ds\n",
    "        else:\n",
    "            dsb = ds[ds['Name'] == bb[i]]\n",
    "        codes, counts = np.unique(dsb['group'], return_counts=True)\n",
    "        print(bb[i])\n",
    "        print(codes, counts)\n",
    "        bp = sns.boxplot(data=dsb,\n",
    "                         x='hmax', y='group',\n",
    "                         ax=ax,\n",
    "                         order=['Runoff', 'Coastal', 'Compound'],\n",
    "                         orient='h',\n",
    "                         color='white', linecolor='black', linewidth=0.75, width=0.7, gap=0.2,\n",
    "                         flierprops=flierprops,\n",
    "                         medianprops=medianprops,\n",
    "                         meanprops=meanpointprops,\n",
    "                         meanline=False,\n",
    "                         showmeans=True,\n",
    "                         patch_artist=True,\n",
    "                         )\n",
    "\n",
    "        ax.set_xlabel('Flood Depth (m)')\n",
    "        ax.set_ylabel('')\n",
    "        ax.set_title('')\n",
    "        ax.set_title(bb[i], loc='center')\n",
    "        kwargs = dict(linestyle='-', linewidth=1, color='grey', alpha=0.9)\n",
    "        ax.grid(visible=True, which='major', axis='x', **kwargs)\n",
    "        kwargs = dict(linestyle='--', linewidth=0.5, color='lightgrey', alpha=0.9)\n",
    "        ax.grid(visible=True, which='minor', axis='x', **kwargs)\n",
    "        ax.set_xscale(\"log\")\n",
    "\n",
    "        ytl_new = []\n",
    "        for c in ['Runoff', 'Coastal', 'Compound']:\n",
    "            try:\n",
    "                ind = codes.tolist().index(c)\n",
    "                count = counts[ind]\n",
    "                text_new = f'{c}\\n(n={count})'\n",
    "                ytl_new.append(text_new)\n",
    "            except:\n",
    "                ytl_new.append('')\n",
    "        ax.set_yticklabels(ytl_new)\n",
    "\n",
    "    plt.setp(axs, xlim=(0, 20), ylim=(-0.5, 2.5))\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.margins(x=0, y=0)\n",
    "    plt.savefig(os.path.join(out_dir, f'building_exposure_{threshold}.png'), dpi=225, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    # Compound minus max individual\n",
    "    ds = gdf[gdf['hmax_class'] == 5]\n",
    "    ds = ds[ds['hmax'] > threshold]\n",
    "\n",
    "    ds2 = ds.copy()\n",
    "    ds2['Name'] = 'Domain'\n",
    "    ds2 = pd.concat([ds, ds2], axis=0, ignore_index=True)\n",
    "\n",
    "    counts = ds2.groupby('Name')['hmax_diff'].count()\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, tight_layout=True, figsize=(6.2, 3), sharex=False, sharey=False)\n",
    "    ax = axs[0]\n",
    "    vp = sns.violinplot(data=ds2,\n",
    "                        x='hmax_diff',\n",
    "                        y='Name',\n",
    "                        ax=ax,\n",
    "                        density_norm='width',\n",
    "                        common_norm=True,\n",
    "                        fill=False, gap=0.05, linewidth=0.75,\n",
    "                        color='black',\n",
    "                        inner_kws=dict(box_width=3, whis_width=0.75, color=\"black\")\n",
    "                        )\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlim(-.1, 2.5)\n",
    "    ax.set_xlabel('Depth Difference (m)\\ncompound - max. individual')\n",
    "    ax.xaxis.grid(color='gray', linestyle='dashed', alpha=0.8)\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.set_title('(a)', loc='center', fontsize=10)\n",
    "    ax.set_yticklabels(labels=[f'P (n={counts[5]})',\n",
    "                               f'LPD (n={counts[2]})',\n",
    "                               f'CF (n={counts[0]})',\n",
    "                               f'OB (n={counts[4]})',\n",
    "                               f'N (n={counts[3]})',\n",
    "                               f'Domain\\n(n={counts[1]})'\n",
    "                               ], rotation=0)\n",
    "\n",
    "    ax = axs[1]\n",
    "    colors = ['black', \"lightgray\", \"gray\", \"darkgray\", \"gray\"]\n",
    "    basin = ['Onslow Bay', 'Lower Pee Dee', 'Neuse', 'Cape Fear', 'Pamlico']\n",
    "    legend_nick = ['OB', 'LPD', 'N', 'CF', 'P']\n",
    "    marker = ['x', \"o\", \"^\", \"s\", \"d\", ]\n",
    "\n",
    "    for i in range(len(basin)):\n",
    "        dd = ds[ds['Name'] == basin[i]]\n",
    "        ax.scatter(x=dd['hmax_diff'], y=dd['gnd_elev'],\n",
    "                   color=colors[i],\n",
    "                   marker=marker[i],\n",
    "                   s=20, edgecolors='black', alpha=0.9,\n",
    "                   )\n",
    "    ax.legend(legend_nick, loc='upper right', fontsize=10)\n",
    "    ax.set_ylabel('Ground Elevation\\n(m+NAVD88)')\n",
    "    ax.set_xlabel('Depth Difference (m)\\ncompound - max. individual')\n",
    "    ax.xaxis.grid(color='gray', linestyle='dashed', alpha=0.8)\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.set_xlim(0, 2.1)\n",
    "    ax.set_title('(b)', loc='center', fontsize=10)\n",
    "    # ax.set_xscale('log')\n",
    "\n",
    "    #plt.savefig(os.path.join(out_dir, f'building_exposure_{threshold}_wlDiff.png'), dpi=225, bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
