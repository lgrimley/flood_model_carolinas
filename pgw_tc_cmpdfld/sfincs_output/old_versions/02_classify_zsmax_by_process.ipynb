{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7119e9d7-cc46-4e23-a1b3-ac0776b45e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import hydromt\n",
    "from hydromt import DataCatalog\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from hydromt_sfincs import SfincsModel, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "399f4245-8745-4c56-9542-0ad89c3bc25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nScript:\\nAuthor: L Grimley\\nLast Updated: 8/20/24\\n\\nDescription: \\n\\n\\nInputs:\\n\\nOutputs:\\nFor all runs, the ensemble mean and the ensemble max\\n\\n- pgw_drivers_classified.nc\\n- pgw_compound_extent.nc\\n- pgw_drivers_classified_cellCount.csv\\n- pgw_WL_maxCmpd_minus_maxIndiv.nc\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Script:\n",
    "Author: L Grimley\n",
    "Last Updated: 8/20/24\n",
    "\n",
    "Description: \n",
    "\n",
    "\n",
    "Inputs:\n",
    "\n",
    "Outputs:\n",
    "For all runs, the ensemble mean and the ensemble max\n",
    "\n",
    "- pgw_drivers_classified.nc\n",
    "- pgw_compound_extent.nc\n",
    "- pgw_drivers_classified_cellCount.csv\n",
    "- pgw_WL_maxCmpd_minus_maxIndiv.nc\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ac38d03-9cc8-4a59-8da8-959f9e7c24f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Outputs:\n",
    "#       da_classified         a data array with the zsmax attributed to processes (codes 0 to 4)\n",
    "#       fld_cells_by_driver   a numpy array with the total number of grid cells for each process\n",
    "#       da_compound           a data array of the cells where compound flooding occurred (e.g., 0 and 1)\n",
    "#       da_diff               a data array of the diff in waterlevel compound minus max. single driver\n",
    "\n",
    "def classify_zsmax_by_driver(da, compound_key, runoff_key, coastal_key, name_out, hmin, mask):\n",
    "    # Calculate the max water level at each cell across the coastal and runoff drivers\n",
    "    da_single_max = da.sel(run=[runoff_key, coastal_key]).max('run')\n",
    "    \n",
    "    # Calculate the difference between the max water level of the compound and the max of the individual drivers\n",
    "    da_diff = (da.sel(run=compound_key) - da_single_max).compute()\n",
    "    da_diff.name = 'diff in waterlevel compound minus max. single driver'\n",
    "    da_diff.attrs.update(unit='m')\n",
    "\n",
    "    # Create masks based on the driver that caused the max water level given a depth threshold hmin\n",
    "    compound_mask = da_diff > hmin\n",
    "    coastal_mask = da.sel(run=coastal_key).fillna(0) > da.sel(run=[runoff_key]).fillna(0).max('run')\n",
    "    runoff_mask = da.sel(run=runoff_key).fillna(0) > da.sel(run=[coastal_key]).fillna(0).max('run')\n",
    "    assert ~np.logical_and(runoff_mask, coastal_mask).any()\n",
    "    da_classified = (xr.where(coastal_mask, x=compound_mask + 1, y=0)\n",
    "                     + xr.where(runoff_mask, x=compound_mask + 3, y=0)).compute()\n",
    "    da_classified.name = name_out\n",
    "    \n",
    "    # Calculate the number of cells that are attributed to the different drivers\n",
    "    unique_codes, fld_area_by_driver = np.unique(da_classified.data, return_counts=True)\n",
    "\n",
    "    # Mask out the water bodies!!!\n",
    "    da_classified_masked = da_classified.where(mask == 0.0)\n",
    "    unique_codes, fld_area_by_driver_Mask = np.unique(da_classified_masked.data, return_counts=True)\n",
    "    \n",
    "    # Return compound only locations\n",
    "    da_compound = xr.where(compound_mask, x=1, y=0)\n",
    "    da_compound.name = name_out\n",
    "\n",
    "    return da_classified, fld_area_by_driver, da_compound, da_diff, fld_area_by_driver_Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13c7cc05-3c03-45d1-a680-bf5578099ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a SFINCS model and get elevation\n",
    "yml_base = r'Z:\\Data-Expansion\\users\\lelise\\data\\data_catalog_BASE_Carolinas.yml'\n",
    "root = r'Z:\\Data-Expansion\\users\\lelise\\projects\\Carolinas_SFINCS\\Chapter2_PGW\\sfincs\\01_AGU2023\\future_florence\\future_florence_ensmean'\n",
    "mod = SfincsModel(root=root, mode='r', data_libs=[yml_base])\n",
    "dep = mod.grid['dep']\n",
    "\n",
    "# Load coastal waterbody shapefile\n",
    "coastal_wb = mod.data_catalog.get_geodataframe('carolinas_coastal_wb')\n",
    "coastal_wb = coastal_wb.to_crs(mod.crs)\n",
    "coastal_wb_clip = coastal_wb.clip(mod.region)\n",
    "coastal_wb_clip['mask'] = 1.0\n",
    "mask1 = dep.raster.rasterize(coastal_wb_clip, \"mask\", nodata=0.0, all_touched=False)\n",
    "carolinas_nhd_area_rivers = mod.data_catalog.get_geodataframe('carolinas_nhd_area_rivers', geom=mod.region)\n",
    "carolinas_nhd_area_rivers = carolinas_nhd_area_rivers.to_crs(mod.crs)\n",
    "carolinas_nhd_area_rivers['mask'] = 1.0\n",
    "mask2 = dep.raster.rasterize(carolinas_nhd_area_rivers, \"mask\", nodata=0.0, all_touched=True)\n",
    "mask = (mask1 + mask2).compute()\n",
    "mask = xr.where(cond = mask > 0.0, x= 1.0,y=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c16dd385-01ca-495a-91fc-70d7b77410c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = r'Z:\\Data-Expansion\\users\\lelise\\projects\\Carolinas_SFINCS\\Chapter2_PGW\\sfincs\\03_OBS\\analysis_2'\n",
    "out_dir = os.path.join(work_dir, 'driver_analysis')\n",
    "if os.path.exists(out_dir) is False:\n",
    "    os.makedirs(out_dir)\n",
    "os.chdir(out_dir)\n",
    "\n",
    "storms = ['flor', 'floy', 'matt']\n",
    "climates = ['pres', 'fut']\n",
    "hmin = 0.05  # minimum difference between the individual and compound drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eae0c346-4a6b-4f7a-9749-04df18b24b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Parse the drivers for each simulation '''\n",
    "# Load the peak water levels for all simulations\n",
    "zsmax_file = os.path.join(work_dir, 'zsmax', 'pgw_zsmax.nc')\n",
    "da_zsmax = xr.open_dataarray(zsmax_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "162c7cd8-a3fe-4bf0-9fb0-16fdab54e08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "flor_pres\n",
      "floy_pres\n",
      "floy_pres\n",
      "floy_pres\n",
      "floy_pres\n",
      "floy_pres\n",
      "floy_pres\n",
      "floy_pres\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 70\u001b[0m\n\u001b[0;32m     68\u001b[0m                     run_ids\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mda_compound\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     69\u001b[0m                     \u001b[38;5;66;03m# Write the compound extent to a tif for viewing\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m                     \u001b[43mda_compound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_raster\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mda_compound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.tif\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m9999.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m                     \u001b[38;5;28mprint\u001b[39m(da_compound\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Concatenate the data arrays\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\hydromt-sfincs-v1.1.0\\Lib\\site-packages\\hydromt\\raster.py:2803\u001b[0m, in \u001b[0;36mRasterDataArray.to_raster\u001b[1;34m(self, raster_path, driver, dtype, tags, windowed, mask, logger, overviews, overviews_resampling, **profile_kwargs)\u001b[0m\n\u001b[0;32m   2801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile_kwargs:\n\u001b[0;32m   2802\u001b[0m     profile\u001b[38;5;241m.\u001b[39mupdate(profile_kwargs)\n\u001b[1;32m-> 2803\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrasterio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraster_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprofile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2804\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwindowed\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2805\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwindow_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock_windows\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mrasterio\\\\_base.pyx:450\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__exit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mrasterio\\\\_base.pyx:441\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.close\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\hydromt-sfincs-v1.1.0\\Lib\\contextlib.py:609\u001b[0m, in \u001b[0;36mExitStack.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    608\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Immediately unwind the context stack.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 609\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__exit__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\hydromt-sfincs-v1.1.0\\Lib\\contextlib.py:558\u001b[0m, in \u001b[0;36mExitStack.__exit__\u001b[1;34m(self, *exc_details)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m--> 558\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mexc_details):\n\u001b[0;32m    559\u001b[0m     received_exc \u001b[38;5;241m=\u001b[39m exc_details[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;66;03m# We manipulate the exception state so it behaves as though\u001b[39;00m\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;66;03m# we were actually nesting multiple with statements\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fld_cells = pd.DataFrame()  # dataframe populated with total flooded area\n",
    "fld_cells_mask = pd.DataFrame()  # dataframe populated with total flooded area\n",
    "fld_da_compound = []  # populated with data arrays of the compound areas for each run\n",
    "fld_da_classified = []\n",
    "fld_da_diff = []\n",
    "cc_run_ids = []\n",
    "run_ids = []  # keep track of the run IDs and their order\n",
    "# Loop through and classify flooding by driver\n",
    "for storm in storms:\n",
    "    nruns = 8\n",
    "    if storm == 'matt':\n",
    "        nruns = 7\n",
    "    for climate in climates:\n",
    "        if climate == 'pres':\n",
    "            # Get the model names to query zsmax results from data array\n",
    "            compound_key, runoff_key, coastal_key = [f'{storm}_{climate}_compound',\n",
    "                                                     f'{storm}_{climate}_runoff',\n",
    "                                                     f'{storm}_{climate}_coastal']\n",
    "            nameout = f'{storm}_{climate}'\n",
    "\n",
    "            # Attribute max water levels to coastal, runoff or compound processes\n",
    "            out = classify_zsmax_by_driver(da=da_zsmax,  # data array with zsmax for all simulations\n",
    "                                           compound_key=compound_key,\n",
    "                                           runoff_key=runoff_key,\n",
    "                                           coastal_key=coastal_key,\n",
    "                                           name_out=nameout,\n",
    "                                           hmin=hmin,  # depth difference threshold for compound vs. individual\n",
    "                                           mask=mask\n",
    "                                           )\n",
    "            da_classified, fld_cells_by_driver, da_compound, da_diff, fld_cells_by_driver_Mask = out\n",
    "\n",
    "            # Append all the output from the function above to lists\n",
    "            fld_da_classified.append(da_classified)\n",
    "            fld_cells[f'{da_compound.name}'] = fld_cells_by_driver\n",
    "            fld_cells_mask[f'{da_compound.name}'] = fld_cells_by_driver_Mask\n",
    "            fld_da_compound.append(da_compound)\n",
    "            fld_da_diff.append(da_diff)\n",
    "            run_ids.append(f'{da_compound.name}')\n",
    "            print(da_compound.name)\n",
    "\n",
    "        if climate == 'fut':\n",
    "            for sf in np.arange(1, nruns, 1):\n",
    "                for slr in np.arange(1, 6, 1):\n",
    "                    compound_key, runoff_key, coastal_key = [f'{storm}_{climate}_SF{sf}_SLR{slr}_compound',\n",
    "                                                             f'{storm}_{climate}_SF{sf}_runoff',\n",
    "                                                             f'{storm}_{climate}_SF{sf}_SLR{slr}_coastal']\n",
    "\n",
    "                    nameout = f'{storm}_{climate}_SF{sf}_SLR{slr}'\n",
    "                    out = classify_zsmax_by_driver(da=da_zsmax,\n",
    "                                                   compound_key=compound_key,\n",
    "                                                   runoff_key=runoff_key,\n",
    "                                                   coastal_key=coastal_key,\n",
    "                                                   name_out=nameout,\n",
    "                                                   hmin=hmin,\n",
    "                                                   mask=mask\n",
    "                                                   )\n",
    "                    # Append the classified data array (e.g., coastal, runoff, compound) to the larger list\n",
    "                    fld_da_classified.append(da_classified)\n",
    "                    # Append the count of flooded cells by driver to the dataframe\n",
    "                    fld_cells[f'{da_compound.name}'] = fld_cells_by_driver\n",
    "                    # Append the count of flooded cells by driver using a mask to the dataframe\n",
    "                    fld_cells_mask[f'{da_compound.name}'] = fld_cells_by_driver_Mask\n",
    "                    # Append the compound extent data array to the larger list\n",
    "                    fld_da_compound.append(da_compound)\n",
    "                    # Append the difference between the compound and the max single driver data array to the larger list\n",
    "                    fld_da_diff.append(da_diff)\n",
    "                    # Append the run ID to the larger list, used for saving as a run index\n",
    "                    run_ids.append(f'{da_compound.name}')\n",
    "                    # Write the compound extent to a tif for viewing\n",
    "                    da_compound.raster.to_raster(f'{da_compound.name}.tif', nodata=-9999.0)\n",
    "                    print(da_compound.name)\n",
    "\n",
    "# Concatenate the data arrays\n",
    "fld_da_classified = xr.concat(fld_da_classified, dim='run')\n",
    "fld_da_classified['run'] = xr.IndexVariable('run', run_ids)\n",
    "fld_da_classified.to_netcdf('pgw_drivers_classified_all.nc')\n",
    "\n",
    "fld_da_compound = xr.concat(fld_da_compound, dim='run')\n",
    "fld_da_compound['run'] = xr.IndexVariable('run', run_ids)\n",
    "fld_da_compound.to_netcdf('pgw_compound_extent_all.nc')\n",
    "\n",
    "# Cleanup flood area dataframe\n",
    "fld_cells.index = ['no_flood', 'coastal', 'compound_coastal', 'runoff', 'compound_runoff']\n",
    "fld_cells = pd.DataFrame(fld_cells)\n",
    "fld_cells.to_csv('pgw_drivers_classified_all_cellCount.csv')\n",
    "\n",
    "# Cleanup flood area dataframe\n",
    "fld_cells_mask.index = ['no_flood', 'coastal', 'compound_coastal', 'runoff', 'compound_runoff', 'masked']\n",
    "fld_cells_mask = pd.DataFrame(fld_cells_mask)\n",
    "fld_cells_mask.to_csv('pgw_drivers_classified_all_cellCount_waterMask_rivers.csv')\n",
    "\n",
    "fld_da_diff = xr.concat(fld_da_diff, dim='run')\n",
    "fld_da_diff['run'] = xr.IndexVariable('run', run_ids)\n",
    "fld_da_diff.to_netcdf('pgw_WL_maxCmpd_minus_maxIndiv_all.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2166e325-4533-4021-b16a-cb35315fa15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Parse the drivers of the ensemble mean '''\n",
    "os.chdir(r'Z:\\Data-Expansion\\users\\lelise\\projects\\Carolinas_SFINCS\\Chapter2_PGW\\sfincs\\03_OBS\\analysis_2\\ensemble_mean')\n",
    "for type in ['mean', 'max']:\n",
    "    zsmax_file = os.path.join(work_dir, 'zsmax', f'fut_ensemble_zsmax_{type}.nc')\n",
    "    da_ensmean = xr.open_dataarray(zsmax_file)\n",
    "\n",
    "    # if os.path.exists(f'pgw_drivers_classified_ensmean_{type}.nc') is False:\n",
    "    fld_cells = pd.DataFrame()  # dataframe populated with total flooded area\n",
    "    fld_cells_mask = pd.DataFrame()  # dataframe populated with total flooded area\n",
    "    fld_da_compound = []  # populated with data arrays of the compound areas for each run\n",
    "    fld_da_classified = []\n",
    "    fld_da_diff = []\n",
    "    run_ids = []\n",
    "    for storm in ['flor', 'floy', 'matt']:\n",
    "        for climate in ['fut']:\n",
    "            compound_key, runoff_key, coastal_key = [f'{storm}_{climate}_compound_{type}',\n",
    "                                                     f'{storm}_{climate}_runoff_{type}',\n",
    "                                                     f'{storm}_{climate}_coastal_{type}']\n",
    "            out = classify_zsmax_by_driver(da=da_ensmean,\n",
    "                                           compound_key=compound_key, runoff_key=runoff_key,\n",
    "                                           coastal_key=coastal_key, name_out=f'{storm}_{climate}_ensmean',\n",
    "                                           hmin=0.05,\n",
    "                                           mask=mask\n",
    "                                          )\n",
    "            da_classified, fld_cells_by_driver, da_compound, da_diff, fld_cells_by_driver_Mask = out\n",
    "\n",
    "            # Append the classified data array (e.g., coastal, runoff, compound) to the larger list\n",
    "            fld_da_classified.append(da_classified)\n",
    "            # Append the count of flooded cells by driver to the dataframe\n",
    "            fld_cells[f'{da_compound.name}'] = fld_cells_by_driver\n",
    "            # Append the count of flooded cells by driver using a mask to the dataframe\n",
    "            fld_cells_mask[f'{da_compound.name}'] = fld_cells_by_driver_Mask\n",
    "            # Append the compound extent data array to the larger list\n",
    "            fld_da_compound.append(da_compound)\n",
    "            # Append the difference between the compound and the max single driver data array to the larger list\n",
    "            fld_da_diff.append(da_diff)\n",
    "            # Append the run ID to the larger list, used for saving as a run index\n",
    "            run_ids.append(f'{da_compound.name}')\n",
    "            # Write the compound extent to a tif for viewing\n",
    "            da_compound.raster.to_raster(f'{da_compound.name}.tif', nodata=-9999.0)\n",
    "            print(da_compound.name)\n",
    "\n",
    "    # Concatenate the data arrays\n",
    "    fld_da_compound = xr.concat(fld_da_compound, dim='run')\n",
    "    fld_da_compound['run'] = xr.IndexVariable('run', run_ids)\n",
    "    fld_da_compound.to_netcdf(f'pgw_compound_extent_ensmean_{type}.nc')\n",
    "    \n",
    "    fld_da_classified = xr.concat(fld_da_classified, dim='run')\n",
    "    fld_da_classified['run'] = xr.IndexVariable('run', run_ids)\n",
    "    fld_da_classified.to_netcdf(f'pgw_drivers_classified_ensmean_{type}.nc')\n",
    "\n",
    "    fld_da_diff = xr.concat(fld_da_diff, dim='run')\n",
    "    fld_da_diff['run'] = xr.IndexVariable('run', run_ids)\n",
    "    fld_da_diff.to_netcdf(f'pgw_WL_maxCmpd_minus_maxIndiv_ensmean_{type}.nc')\n",
    "\n",
    "    # Cleanup flood area dataframe\n",
    "    # No Flood = 0, Coastal = 1, Compound-coastal = 2, Runoff = 3, Compound-runoff = 4\n",
    "    fld_cells.index = ['no_flood', 'coastal', 'compound_coastal', 'runoff', 'compound_runoff']\n",
    "    fld_cells = pd.DataFrame(fld_cells)\n",
    "    fld_cells.to_csv(f'pgw_drivers_classified_ensmean_{type}_cellCount.csv')\n",
    "\n",
    "    # Cleanup flood area dataframe\n",
    "    # No Flood = 0, Coastal = 1, Compound-coastal = 2, Runoff = 3, Compound-runoff = 4, np.Nan = 5\n",
    "    print(fld_cells_mask)\n",
    "    fld_cells_mask.index = ['no_flood', 'coastal', 'compound_coastal', 'runoff', 'compound_runoff', 'masked']\n",
    "    fld_cells_mask = pd.DataFrame(fld_cells_mask)\n",
    "    fld_cells_mask.to_csv(f'pgw_drivers_classified_ensmean_{type}_cellCount_waterMask_rivers.csv')\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642513f4-b38d-4fcf-a26f-f8f6ed3b25e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
