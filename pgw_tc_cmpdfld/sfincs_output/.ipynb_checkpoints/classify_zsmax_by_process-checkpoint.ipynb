{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7119e9d7-cc46-4e23-a1b3-ac0776b45e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import hydromt\n",
    "from hydromt import DataCatalog\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from hydromt_sfincs import SfincsModel, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "399f4245-8745-4c56-9542-0ad89c3bc25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nScript:\\nAuthor: L Grimley\\nLast Updated: 8/20/24\\n\\nDescription: \\n\\n\\nInputs:\\n\\nOutputs:\\n\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Script:\n",
    "Author: L Grimley\n",
    "Last Updated: 8/20/24\n",
    "\n",
    "Description: \n",
    "\n",
    "\n",
    "Inputs:\n",
    "\n",
    "Outputs:\n",
    "For all runs, the ensemble mean and the ensemble max\n",
    "\n",
    "- pgw_drivers_classified.nc\n",
    "- pgw_compound_extent.nc\n",
    "- pgw_drivers_classified_cellCount.csv\n",
    "- pgw_WL_maxCmpd_minus_maxIndiv.nc\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ac38d03-9cc8-4a59-8da8-959f9e7c24f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Outputs:\n",
    "#       da_classified         a data array with the zsmax attributed to processes (codes 0 to 4)\n",
    "#       fld_cells_by_driver   a numpy array with the total number of grid cells for each process\n",
    "#       da_compound           a data array of the cells where compound flooding occurred (e.g., 0 and 1)\n",
    "#       da_diff               a data array of the diff in waterlevel compound minus max. single driver\n",
    "\n",
    "def classify_zsmax_by_driver(da, compound_key, runoff_key, coastal_key, name_out, hmin):\n",
    "    # Calculate the max water level at each cell across the coastal and runoff drivers\n",
    "    da_single_max = da.sel(run=[runoff_key, coastal_key]).max('run')\n",
    "    \n",
    "    # Calculate the difference between the max water level of the compound and the max of the individual drivers\n",
    "    da_diff = (da.sel(run=compound_key) - da_single_max).compute()\n",
    "    da_diff.name = 'diff in waterlevel compound minus max. single driver'\n",
    "    da_diff.attrs.update(unit='m')\n",
    "\n",
    "    # Create masks based on the driver that caused the max water level given a depth threshold hmin\n",
    "    compound_mask = da_diff > hmin\n",
    "    coastal_mask = da.sel(run=coastal_key).fillna(0) > da.sel(run=[runoff_key]).fillna(0).max('run')\n",
    "    runoff_mask = da.sel(run=runoff_key).fillna(0) > da.sel(run=[coastal_key]).fillna(0).max('run')\n",
    "    assert ~np.logical_and(runoff_mask, coastal_mask).any()\n",
    "    da_classified = (xr.where(coastal_mask, x=compound_mask + 1, y=0)\n",
    "                     + xr.where(runoff_mask, x=compound_mask + 3, y=0)).compute()\n",
    "    da_classified.name = name_out\n",
    "\n",
    "    # Calculate the number of cells that are attributed to the different drivers\n",
    "    unique_codes, fld_area_by_driver = np.unique(da_classified.data, return_counts=True)\n",
    "\n",
    "    # Return compound only locations\n",
    "    da_compound = xr.where(compound_mask, x=1, y=0)\n",
    "    da_compound.name = name_out\n",
    "\n",
    "    return da_classified, fld_area_by_driver, da_compound, da_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d8cdb0a-c0c0-4412-8e68-8573a8e8de4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = r'Z:\\users\\lelise\\projects\\Carolinas_SFINCS\\Chapter2_PGW\\sfincs\\03_OBS\\analysis_2'\n",
    "out_dir = os.path.join(work_dir, 'driver_analysis')\n",
    "if os.path.exists(out_dir) is False:\n",
    "    os.makedirs(out_dir)\n",
    "os.chdir(out_dir)\n",
    "\n",
    "storms = ['flor', 'floy', 'matt']\n",
    "climates = ['pres', 'fut']\n",
    "hmin = 0.05  # minimum difference between the individual and compound drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eae0c346-4a6b-4f7a-9749-04df18b24b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Parse the drivers for each simulation '''\n",
    "# Load the peak water levels for all simulations\n",
    "zsmax_file = os.path.join(work_dir, 'zsmax', 'pgw_zsmax.nc')\n",
    "da_zsmax = xr.open_dataarray(zsmax_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "162c7cd8-a3fe-4bf0-9fb0-16fdab54e08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flor_pres\n",
      "flor_fut_SF1_SLR1\n",
      "flor_fut_SF1_SLR2\n",
      "flor_fut_SF1_SLR3\n",
      "flor_fut_SF1_SLR4\n",
      "flor_fut_SF1_SLR5\n",
      "flor_fut_SF2_SLR1\n",
      "flor_fut_SF2_SLR2\n",
      "flor_fut_SF2_SLR3\n",
      "flor_fut_SF2_SLR4\n",
      "flor_fut_SF2_SLR5\n",
      "flor_fut_SF3_SLR1\n",
      "flor_fut_SF3_SLR2\n",
      "flor_fut_SF3_SLR3\n",
      "flor_fut_SF3_SLR4\n",
      "flor_fut_SF3_SLR5\n",
      "flor_fut_SF4_SLR1\n",
      "flor_fut_SF4_SLR2\n",
      "flor_fut_SF4_SLR3\n",
      "flor_fut_SF4_SLR4\n",
      "flor_fut_SF4_SLR5\n",
      "flor_fut_SF5_SLR1\n",
      "flor_fut_SF5_SLR2\n",
      "flor_fut_SF5_SLR3\n",
      "flor_fut_SF5_SLR4\n",
      "flor_fut_SF5_SLR5\n",
      "flor_fut_SF6_SLR1\n",
      "flor_fut_SF6_SLR2\n",
      "flor_fut_SF6_SLR3\n",
      "flor_fut_SF6_SLR4\n",
      "flor_fut_SF6_SLR5\n",
      "flor_fut_SF7_SLR1\n",
      "flor_fut_SF7_SLR2\n",
      "flor_fut_SF7_SLR3\n",
      "flor_fut_SF7_SLR4\n",
      "flor_fut_SF7_SLR5\n",
      "floy_pres\n",
      "floy_fut_SF1_SLR1\n",
      "floy_fut_SF1_SLR2\n",
      "floy_fut_SF1_SLR3\n",
      "floy_fut_SF1_SLR4\n",
      "floy_fut_SF1_SLR5\n",
      "floy_fut_SF2_SLR1\n",
      "floy_fut_SF2_SLR2\n",
      "floy_fut_SF2_SLR3\n",
      "floy_fut_SF2_SLR4\n",
      "floy_fut_SF2_SLR5\n",
      "floy_fut_SF3_SLR1\n",
      "floy_fut_SF3_SLR2\n",
      "floy_fut_SF3_SLR3\n",
      "floy_fut_SF3_SLR4\n",
      "floy_fut_SF3_SLR5\n",
      "floy_fut_SF4_SLR1\n",
      "floy_fut_SF4_SLR2\n",
      "floy_fut_SF4_SLR3\n",
      "floy_fut_SF4_SLR4\n",
      "floy_fut_SF4_SLR5\n",
      "floy_fut_SF5_SLR1\n",
      "floy_fut_SF5_SLR2\n",
      "floy_fut_SF5_SLR3\n",
      "floy_fut_SF5_SLR4\n",
      "floy_fut_SF5_SLR5\n",
      "floy_fut_SF6_SLR1\n",
      "floy_fut_SF6_SLR2\n",
      "floy_fut_SF6_SLR3\n",
      "floy_fut_SF6_SLR4\n",
      "floy_fut_SF6_SLR5\n",
      "floy_fut_SF7_SLR1\n",
      "floy_fut_SF7_SLR2\n",
      "floy_fut_SF7_SLR3\n",
      "floy_fut_SF7_SLR4\n",
      "floy_fut_SF7_SLR5\n",
      "matt_pres\n",
      "matt_fut_SF1_SLR1\n",
      "matt_fut_SF1_SLR2\n",
      "matt_fut_SF1_SLR3\n",
      "matt_fut_SF1_SLR4\n",
      "matt_fut_SF1_SLR5\n",
      "matt_fut_SF2_SLR1\n",
      "matt_fut_SF2_SLR2\n",
      "matt_fut_SF2_SLR3\n",
      "matt_fut_SF2_SLR4\n",
      "matt_fut_SF2_SLR5\n",
      "matt_fut_SF3_SLR1\n",
      "matt_fut_SF3_SLR2\n",
      "matt_fut_SF3_SLR3\n",
      "matt_fut_SF3_SLR4\n",
      "matt_fut_SF3_SLR5\n",
      "matt_fut_SF4_SLR1\n",
      "matt_fut_SF4_SLR2\n",
      "matt_fut_SF4_SLR3\n",
      "matt_fut_SF4_SLR4\n",
      "matt_fut_SF4_SLR5\n",
      "matt_fut_SF5_SLR1\n",
      "matt_fut_SF5_SLR2\n",
      "matt_fut_SF5_SLR3\n",
      "matt_fut_SF5_SLR4\n",
      "matt_fut_SF5_SLR5\n",
      "matt_fut_SF6_SLR1\n",
      "matt_fut_SF6_SLR2\n",
      "matt_fut_SF6_SLR3\n",
      "matt_fut_SF6_SLR4\n",
      "matt_fut_SF6_SLR5\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('pgw_drivers_classified_all.nc') is False:\n",
    "    fld_cells = pd.DataFrame()  # dataframe populated with total flooded area\n",
    "    fld_da_compound = []  # populated with data arrays of the compound areas for each run\n",
    "    fld_da_classified = []\n",
    "    fld_da_diff = []\n",
    "    cc_run_ids = []\n",
    "    run_ids = []  # keep track of the run IDs and their order\n",
    "    # Loop through and classify flooding by driver\n",
    "    for storm in storms:\n",
    "        nruns = 8\n",
    "        if storm == 'matt':\n",
    "            nruns = 7\n",
    "        for climate in climates:\n",
    "            if climate == 'pres':\n",
    "                # Get the model names to query zsmax results from data array\n",
    "                compound_key, runoff_key, coastal_key = [f'{storm}_{climate}_compound',\n",
    "                                                         f'{storm}_{climate}_runoff',\n",
    "                                                         f'{storm}_{climate}_coastal']\n",
    "                nameout = f'{storm}_{climate}'\n",
    "\n",
    "                # Attribute max water levels to coastal, runoff or compound processes\n",
    "                out = classify_zsmax_by_driver(da=da_zsmax,  # data array with zsmax for all simulations\n",
    "                                               compound_key=compound_key,\n",
    "                                               runoff_key=runoff_key,\n",
    "                                               coastal_key=coastal_key,\n",
    "                                               name_out=nameout,\n",
    "                                               hmin=hmin  # depth difference threshold for compound vs. individual\n",
    "                                               )\n",
    "                da_classified, fld_cells_by_driver, da_compound, da_diff = out\n",
    "\n",
    "                # Append all the output from the function above to lists\n",
    "                fld_da_classified.append(da_classified)\n",
    "                fld_cells[f'{da_compound.name}'] = fld_cells_by_driver\n",
    "                fld_da_compound.append(da_compound)\n",
    "                fld_da_diff.append(da_diff)\n",
    "                run_ids.append(f'{da_compound.name}')\n",
    "                print(da_compound.name)\n",
    "\n",
    "            if climate == 'fut':\n",
    "                for sf in np.arange(1, nruns, 1):\n",
    "                    for slr in np.arange(1, 6, 1):\n",
    "                        compound_key, runoff_key, coastal_key = [f'{storm}_{climate}_SF{sf}_SLR{slr}_compound',\n",
    "                                                                 f'{storm}_{climate}_SF{sf}_runoff',\n",
    "                                                                 f'{storm}_{climate}_SF{sf}_SLR{slr}_coastal']\n",
    "\n",
    "                        nameout = f'{storm}_{climate}_SF{sf}_SLR{slr}'\n",
    "                        out = classify_zsmax_by_driver(da=da_zsmax,\n",
    "                                                       compound_key=compound_key,\n",
    "                                                       runoff_key=runoff_key,\n",
    "                                                       coastal_key=coastal_key,\n",
    "                                                       name_out=nameout,\n",
    "                                                       hmin=hmin\n",
    "                                                       )\n",
    "\n",
    "                        da_classified, fld_cells_by_driver, da_compound, da_diff = out\n",
    "                        fld_da_classified.append(da_classified)\n",
    "                        fld_cells[f'{da_compound.name}'] = fld_cells_by_driver\n",
    "                        fld_da_compound.append(da_compound)\n",
    "                        fld_da_diff.append(da_diff)\n",
    "                        run_ids.append(f'{da_compound.name}')\n",
    "                        print(da_compound.name)\n",
    "\n",
    "    # Concatenate the data arrays\n",
    "    fld_da_classified = xr.concat(fld_da_classified, dim='run')\n",
    "    fld_da_classified['run'] = xr.IndexVariable('run', run_ids)\n",
    "    fld_da_classified.to_netcdf('pgw_drivers_classified_all.nc')\n",
    "\n",
    "    fld_da_compound = xr.concat(fld_da_compound, dim='run')\n",
    "    fld_da_compound['run'] = xr.IndexVariable('run', run_ids)\n",
    "    fld_da_compound.to_netcdf('pgw_compound_extent_all.nc')\n",
    "\n",
    "    # Cleanup flood area dataframe\n",
    "    fld_cells.index = ['no_flood', 'coastal', 'compound_coastal', 'runoff', 'compound_runoff']\n",
    "    fld_cells = pd.DataFrame(fld_cells)\n",
    "    fld_cells.to_csv('pgw_drivers_classified_all_cellCount.csv')\n",
    "\n",
    "    fld_da_diff = xr.concat(fld_da_diff, dim='run')\n",
    "    fld_da_diff['run'] = xr.IndexVariable('run', run_ids)\n",
    "    fld_da_diff.to_netcdf('pgw_WL_maxCmpd_minus_maxIndiv_all.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2166e325-4533-4021-b16a-cb35315fa15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flor_fut_ensmean\n",
      "floy_fut_ensmean\n",
      "matt_fut_ensmean\n",
      "flor_fut_ensmean\n",
      "floy_fut_ensmean\n",
      "matt_fut_ensmean\n"
     ]
    }
   ],
   "source": [
    "''' Parse the drivers of the ensemble mean '''\n",
    "for type in ['mean', 'max']:\n",
    "    zsmax_file = os.path.join(work_dir, 'zsmax', f'fut_ensemble_zsmax_{type}.nc')\n",
    "    da_ensmean = xr.open_dataarray(zsmax_file)\n",
    "\n",
    "    # if os.path.exists(f'pgw_drivers_classified_ensmean_{type}.nc') is False:\n",
    "    fld_cells = pd.DataFrame()  # dataframe populated with total flooded area\n",
    "    fld_da_compound = []  # populated with data arrays of the compound areas for each run\n",
    "    fld_da_classified = []\n",
    "    fld_da_diff = []\n",
    "    run_ids = []\n",
    "    for storm in ['flor', 'floy', 'matt']:\n",
    "        for climate in ['fut']:\n",
    "            compound_key, runoff_key, coastal_key = [f'{storm}_{climate}_compound_{type}',\n",
    "                                                     f'{storm}_{climate}_runoff_{type}',\n",
    "                                                     f'{storm}_{climate}_coastal_{type}']\n",
    "            out = classify_zsmax_by_driver(da=da_ensmean,\n",
    "                                           compound_key=compound_key, runoff_key=runoff_key,\n",
    "                                           coastal_key=coastal_key, name_out=f'{storm}_{climate}_ensmean',\n",
    "                                           hmin=0.05)\n",
    "            da_classified, fld_cells_by_driver, da_compound, da_diff = out\n",
    "            fld_da_classified.append(da_classified)\n",
    "            fld_cells[f'{da_compound.name}'] = fld_cells_by_driver\n",
    "            fld_da_compound.append(da_compound)\n",
    "            fld_da_diff.append(da_diff)\n",
    "            run_ids.append(f'{da_compound.name}')\n",
    "            print(da_compound.name)\n",
    "\n",
    "    # Concatenate the data arrays\n",
    "    fld_da_compound = xr.concat(fld_da_compound, dim='run')\n",
    "    fld_da_compound['run'] = xr.IndexVariable('run', run_ids)\n",
    "    fld_da_compound.to_netcdf(f'pgw_compound_extent_ensmean_{type}.nc')\n",
    "\n",
    "    fld_da_classified = xr.concat(fld_da_classified, dim='run')\n",
    "    fld_da_classified['run'] = xr.IndexVariable('run', run_ids)\n",
    "    fld_da_classified.to_netcdf(f'pgw_drivers_classified_ensmean_{type}.nc')\n",
    "\n",
    "    fld_da_diff = xr.concat(fld_da_diff, dim='run')\n",
    "    fld_da_diff['run'] = xr.IndexVariable('run', run_ids)\n",
    "    fld_da_diff.to_netcdf(f'pgw_WL_maxCmpd_minus_maxIndiv_ensmean_{type}.nc')\n",
    "\n",
    "    # Cleanup flood area dataframe\n",
    "    # No Flood = 0, Coastal = 1, Compound-coastal = 2, Runoff = 3, Compound-runoff = 4\n",
    "    fld_cells.index = ['no_flood', 'coastal', 'compound_coastal', 'runoff', 'compound_runoff']\n",
    "    fld_cells = pd.DataFrame(fld_cells)\n",
    "    fld_cells.to_csv(f'pgw_drivers_classified_ensmean_{type}_cellCount.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d52268-bac4-4739-93c9-c9e10e673868",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
